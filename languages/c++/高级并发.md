## 线程池

	为了能够得到返回值，我们应该把函数先传给std::packaged_task,然后再加入队列，并返回std::packaged_task中的std::future,因为std::packaged_task是move-only的，而std::function又要求存储的函数实例可以拷贝构造，因此这里需要实现一个支持 move-only 类型的函数包裹类，即一个带 call 操作的类型擦除（type-erasure）类

```cpp
#include <memory>
#include <utility>

class FunctionWrapper {
 public:
  FunctionWrapper() = default;

  FunctionWrapper(const FunctionWrapper&) = delete;

  FunctionWrapper& operator=(const FunctionWrapper&) = delete;

  FunctionWrapper(FunctionWrapper&& rhs) noexcept
      : impl_(std::move(rhs.impl_)) {}

  FunctionWrapper& operator=(FunctionWrapper&& rhs) noexcept {
    impl_ = std::move(rhs.impl_);
    return *this;
  }

  template <typename F>
  FunctionWrapper(F&& f) : impl_(new ImplType<F>(std::move(f))) {}

  void operator()() const { impl_->call(); }

 private:
  struct ImplBase {
    virtual void call() = 0;
    virtual ~ImplBase() = default;
  };

  template <typename F>
  struct ImplType : ImplBase {
    ImplType(F&& f) noexcept : f_(std::move(f)) {}
    void call() override { f_(); }

    F f_;
  };

 private:
  std::unique_ptr<ImplBase> impl_;
};
```


-   往线程池添加任务会增加任务队列的竞争，lock-free 队列可以避免这点但存在乒乓缓存的问题。为此需要把任务队列拆分为线程独立的本地队列和全局队列，当线程队列无任务时就去全局队列取任务
-   这可以避免数据竞争，但如果任务分配不均，就会导致某个线程的本地队列中有很多任务，而其他线程无事可做，为此应该让没有工作的线程可以从其他线程获取任务
```cpp
#include <atomic>
#include <deque>
#include <future>
#include <memory>
#include <mutex>
#include <thread>
#include <type_traits>
#include <vector>

#include "concurrent_queue.hpp"
#include "function_wrapper.hpp"

class WorkStealingQueue {
 public:
  WorkStealingQueue() = default;

  WorkStealingQueue(const WorkStealingQueue&) = delete;

  WorkStealingQueue& operator=(const WorkStealingQueue&) = delete;

  void push(FunctionWrapper f) {
    std::lock_guard<std::mutex> l(m_);
    q_.push_front(std::move(f));
  }

  bool empty() const {
    std::lock_guard<std::mutex> l(m_);
    return q_.empty();
  }

  bool try_pop(FunctionWrapper& res) {
    std::lock_guard<std::mutex> l(m_);
    if (q_.empty()) {
      return false;
    }
    res = std::move(q_.front());
    q_.pop_front();
    return true;
  }

  bool try_steal(FunctionWrapper& res) {
    std::lock_guard<std::mutex> l(m_);
    if (q_.empty()) {
      return false;
    }
    res = std::move(q_.back());
    q_.pop_back();
    return true;
  }

 private:
  std::deque<FunctionWrapper> q_;
  mutable std::mutex m_;
};

class ThreadPool {
 public:
  ThreadPool() {
    std::size_t n = std::thread::hardware_concurrency();
    try {
      for (std::size_t i = 0; i < n; ++i) {
        work_stealing_queue_.emplace_back(
            std::make_unique<WorkStealingQueue>());
        threads_.emplace_back(&ThreadPool::worker_thread, this, i);
      }
    } catch (...) {
      done_ = true;
      for (auto& x : threads_) {
        if (x.joinable()) {
          x.join();
        }
      }
      throw;
    }
  }

  ~ThreadPool() {
    done_ = true;
    for (auto& x : threads_) {
      if (x.joinable()) {
        x.join();
      }
    }
  }

  template <typename F>
  std::future<std::invoke_result_t<F>> submit(F f) {
    std::packaged_task<std::invoke_result_t<F>()> task(std::move(f));
    std::future<std::invoke_result_t<F>> res(task.get_future());
    if (local_queue_) {
      local_queue_->push(std::move(task));
    } else {
      pool_queue_.push(std::move(task));
    }
    return res;
  }

 private:
  bool pop_task_from_local_queue(FunctionWrapper& task) {
    return local_queue_ && local_queue_->try_pop(task);
  }

  bool pop_task_from_pool_queue(FunctionWrapper& task) {
    return pool_queue_.try_pop(task);
  }

  bool pop_task_from_other_thread_queue(FunctionWrapper& task) {
    for (std::size_t i = 0; i < work_stealing_queue_.size(); ++i) {
      std::size_t index = (index_ + i + 1) % work_stealing_queue_.size();
      if (work_stealing_queue_[index]->try_steal(task)) {
        return true;
      }
    }
    return false;
  }

  void worker_thread(std::size_t index) {
    index_ = index;
    local_queue_ = work_stealing_queue_[index_].get();
    while (!done_) {
      FunctionWrapper task;
      if (pop_task_from_local_queue(task) || pop_task_from_pool_queue(task) ||
          pop_task_from_other_thread_queue(task)) {
        task();
      } else {
        std::this_thread::yield();
      }
    }
  }

 private:
  std::atomic<bool> done_ = false;
  ConcurrentQueue<FunctionWrapper> pool_queue_;
  std::vector<std::unique_ptr<WorkStealingQueue>> work_stealing_queue_;
  std::vector<std::thread> threads_;

  static thread_local WorkStealingQueue* local_queue_;
  static thread_local std::size_t index_;
};

thread_local WorkStealingQueue* ThreadPool::local_queue_;
thread_local std::size_t ThreadPool::index_;
```


## 可中断的线程

```cpp
#include <atomic>
#include <condition_variable>
#include <mutex>

class InterruptFlag {
 public:
  void set() {
    b_.store(true, std::memory_order_relaxed);
    std::lock_guard<std::mutex> l(m_);
    if (cv_) {
      cv_->notify_all();
    } else if (cv_any_) {
      cv_any_->notify_all();
    }
  }

  template <typename Lockable>
  void wait(std::condition_variable_any& cv, Lockable& l) {
    class Mutex {
     public:
      Mutex(InterruptFlag* self, std::condition_variable_any& cv, Lockable& l)
          : self_(self), lock_(l) {
        self_->m_.lock();
        self_->cv_any_ = &cv;
      }

      ~Mutex() {
        self_->cv_any_ = nullptr;
        self_->m_.unlock();
      }

      void lock() { std::lock(self_->m_, lock_); }

      void unlock() {
        lock_.unlock();
        self_->m_.unlock();
      }

     private:
      InterruptFlag* self_;
      Lockable& lock_;
    };

    Mutex m(this, cv, l);
    interruption_point();
    cv.wait(m);
    interruption_point();
  }
  // rest as before

 private:
  std::atomic<bool> b_;
  std::condition_variable* cv_ = nullptr;
  std::condition_variable_any* cv_any_ = nullptr;
  std::mutex m_;
};

template <typename Lockable>
void interruptible_wait(std::condition_variable_any& cv, Lockable& l) {
  this_thread_interrupt_flag.wait(cv, l);
}
```

-   对于其他阻塞调用（比如 mutex、future）的中断，一般也可以像对 [std::condition_variable](https://en.cppreference.com/w/cpp/thread/condition_variable) 一样设置超时时间，因为不访问内部 mutex 或 future 无法在未满足等待的条件时中断等待
```cpp
template <typename T>
void interruptible_wait(std::future<T>& ft) {
  while (!this_thread_interrupt_flag.is_set()) {
    if (ft.wait_for(std::chrono::milliseconds(1)) ==
        std::future_status::ready) {
      break;
    }
  }
  interruption_point();
}
```
- 从被中断的线程角度来看，中断就是一个 `thread_interrupted` 异常。因此检查出中断后，可以像异常一样对其进行处理
```cpp
internal_thread = std::thread{[f, &p] {
  p.set_value(&this_thread_interrupt_flag);
  try {
    f();
  } catch (const thread_interrupted&) {
    // 异常传入 std::thread 的析构函数时将调用 std::terminate
    // 为了防止程序终止就要捕获异常
  }
}};
```


-   假如有一个桌面搜索程序，除了与用户交互，程序还需要监控文件系统的状态，以识别任何更改并更新其索引。为了避免影响 GUI 的响应性，这个处理通常会交给一个后台线程，后台线程需要运行于程序的整个生命周期。这样的程序通常只在机器关闭时退出，而在其他情况下关闭程序，就需要井然有序地关闭后台线程，一个关闭方式就是中断
```cpp
std::mutex config_mutex;
std::vector<InterruptibleThread> background_threads;

void background_thread(int disk_id) {
  while (true) {
    interruption_point();
    fs_change fsc = get_fs_changes(disk_id);
    if (fsc.has_changes()) {
      update_index(fsc);
    }
  }
}

void start_background_processing() {
  background_threads.emplace_back(background_thread, disk_1);
  background_threads.emplace_back(background_thread, disk_2);
}

int main() {
  start_background_processing();
  process_gui_until_exit();
  std::unique_lock<std::mutex> l(config_mutex);
  for (auto& x : background_threads) {
    x.interrupt();
  }
  // 中断所有线程后再join
  for (auto& x : background_threads) {
    if (x.joinable()) {
      x.join();
    }
  }
  // 不直接在一个循环里中断并 join 的目的是为了并发，
  // 因为中断不会立即完成，它们必须进入下一个中断点，
  // 再在退出前必要地调用析构和异常处理的代码，
  // 如果对每个线程都中断后立即 join，就会造成中断线程的等待，
  // 即使它还可以做一些有用的工作，比如中断其他线程
}
```

## 并行算法

### 执行策略

头文件execution中指定了如下执行策略类
```cpp
std::execution::sequenced_policy
std::execution::parallel_policy
std::execution::parallel_unsequenced_policy
std::execution::unsequenced_policy  // C++20

//对应的全局对象如下
std::execution::seq
std::execution::par//在一个给定线程上的操作必须以确定顺序执行，并且不能相互交错
std::execution::par_unseq//最大可能的并行化,操作可以在单个线程上互相交错
std::execution::unseq  // C++20
```

-   在不指定执行策略时，如下对算法的调用，抛出的异常会被传播
```cpp
std::for_each(v.begin(), v.end(), [](auto x) { throw my_exception(); });
```

-   而指定执行策略时，如果算法执行期间抛出异常，则行为结果由执行策略决定。如果有任何未捕获的异常，执行策略将调用 [std::terminate](https://en.cppreference.com/w/cpp/error/terminate) 终止程序，唯一可能抛出异常的情况是，内部操作不能获取足够的内存资源时抛出 [std::bad_alloc](https://en.cppreference.com/w/cpp/memory/new/bad_alloc)。如下操作将调用 [std::terminate](https://en.cppreference.com/w/cpp/error/terminate) 终止程序
```cpp
std::for_each(std::execution::seq, v.begin(), v.end(),
[](auto x) { throw my_exception(); });
```

一般来说会使用std::execution::par,如果有内部同步机制的话只能用这个，std::execution::par_unseq虽然能使库通过重排和交错任务来提高性能，但它要想保证线程安全就只能在外部使用同步机制确保其他线程不会访问当前数据

内部同步：
```cpp
#include <algorithm>
#include <mutex>
#include <vector>

class A {
 public:
  int get() const {
    std::lock_guard<std::mutex> l(m_);
    return n_;
  }

  void inc() {
    std::lock_guard<std::mutex> l(m_);
    ++n_;
  }

 private:
  mutable std::mutex m_;
  int n_ = 0;
};

void f(std::vector<A>& v) {
  std::for_each(std::execution::par, v.begin(), v.end(), [](A& x) { x.inc(); });
}
```


外部同步：
```cpp
#include <algorithm>
#include <mutex>
#include <vector>

class A {
 public:
  int get() const { return n_; }
  void inc() { ++n_; }

 private:
  int n_ = 0;
};

class B {
 public:
  void lock() { m_.lock(); }
  void unlock() { m_.unlock(); }
  std::vector<A>& get() { return v_; }

 private:
  std::mutex m_;
  std::vector<A> v_;
};

void f(B& x) {
  std::lock_guard<std::mutex> l(x);
  auto& v = x.get();
  std::for_each(std::execution::par_unseq, v.begin(), v.end(),
[](A& x) { x.inc(); });
}
```



### 标准库的并行算法

```cpp
template <class RandomIt>
void sort(RandomIt first, RandomIt last);

template <class RandomIt, class Compare>
void sort(RandomIt first, RandomIt last, Compare comp);

// 并行版对应有两个重载
template <class ExecutionPolicy, class RandomIt>
void sort(ExecutionPolicy&& policy, RandomIt first, RandomIt last);

template <class ExecutionPolicy, class RandomIt, class Compare>
void sort(ExecutionPolicy&& policy, RandomIt first, RandomIt last,
Compare comp);
```

如果常规版本用的是输入迭代器或者输出迭代器，则并行版的重载将使用前向迭代器
```cpp
template <class InputIt, class OutputIt>
OutputIt copy(InputIt first, InputIt last, OutputIt d_first);

template <class ExecutionPolicy, class ForwardIt1, class ForwardIt2>
ForwardIt2 copy(ExecutionPolicy&& policy, ForwardIt1 first, ForwardIt1 last,
ForwardIt2 d_first);
```

输入迭代器和输出迭代器都是单向的，前向迭代器也是单向的，但是它可以存储一个指向之前元素的拷贝，比如std::forward_list::begin,而且前向迭代器不会使其他的迭代器的拷贝失效，这对于并行而言是至关重要的

## 并发相关的 bug 类型

-   与并发直接相关的 bug 一般可以分为两大类，一是 unwanted blocking，二是 race condition
-   unwanted blocking 包含以下几种情况
    -   死锁（deadlock）：两个线程互相等待，导致均无法完成工作。最明显的情况是，如果负责用户界面的线程死锁，界面将失去响应。也有一些情况是，界面可以保持响应，但一些任务无法完成，比如搜索不返回结果，或者文档不被打印
    -   活锁（livelock）：类似于死锁，不同的是线程不是阻塞等待，而是在忙碌于一个检查循环中，比如自旋锁。严重时，其表现的症状就和死锁一样，比如程序不进行，此外由于线程仍在运行，CPU 会处于高使用率状态。在不太严重的情况下，活锁最终会被操作系统的随机调度解决，但仍然会造成任务的长时间延迟，并且延迟期间 CPU 使用率很高
    -   I/O 阻塞或其他外部输入：如果线程阻塞等待外部输入，就无法继续处理工作。因此如果一个线程执行的任务会被其他线程等待，就不要让这个线程等待外部输入
-   许多死锁和活锁都是由于 race condition 造成的，不过很大一部分 race condition 是良性的，比如要处理任务队列的下一个任务，决定用哪个工作线程去处理是无关紧要的。造成问题的 race condtion 包含以下几种情况
    -   数据竞争（data race）：数据竞争是一种特定类型的 race condtion，由于对共享内存位置的不同步的并发访问，它将导致未定义行为。数据竞争通常发生于不正确地使用原子操作来同步线程，或者不加锁访问共享数据
    -   被破坏的不变量（broken invariant）：它可以表现为空悬指针（其他线程可以删除被访问的数据）、随机内存损坏（由于局部更新导致线程读取的值不一致）、双重释放（比如两个线程弹出队列的同一个数据）等。不变量的破坏是暂时的，因为它是基于值的。如果不同线程上的操作要求以一个特定顺序执行，不正确的同步就会导致 race condition，有时就会违反这个执行顺序
    -   生命周期问题（lifetime issue）：这个问题可以归入 broken invariant，但这里单独提出来。这个问题表现为，线程比其访问的数据活得更长。一般这个问题发生于线程引用了超出范围的局部变量，但也不仅限于此，比如调用 [join](https://en.cppreference.com/w/cpp/thread/thread/join)，要考虑异常抛出时，调用不被跳过
-   通常可以通过调试器来确认死锁和活锁的线程以及它们争用的同步对象。对于数据竞争、不变量的破坏、生命周期问题，可见症状（如随机崩溃或不正确的输出）可以显示在代码的任何位置，代码可能重写系统其他部分使用的内存，并且很久以后才被触及，这个错误可能在程序执行的后期出现在与 bug 代码完全无关的位置。这就是共享内存的真正祸端，无论如何限制线程对数据的访问和确保正确的同步，任何线程都可以重写其他线程中的数据



## unwanted blocking

Unwanted blocking（不需要的阻塞）是指在计算机系统或网络中，某些操作、请求或资源因受限制而被阻止执行的现象。这种阻塞可能会对系统性能、用户体验或程序的正常执行造成负面影响。以下是一些关于不需要的阻塞的详细讨论：

1.  同步和异步操作：在计算机编程中，同步操作是指一个操作必须等待另一个操作完成后才能继续执行。异步操作则允许多个操作同时进行，无需等待其他操作完成。如果某个同步操作被阻塞，那么依赖于它的其他操作也会被间接阻塞。在这种情况下，不需要的阻塞可能导致程序性能下降，甚至出现死锁。通过使用异步操作，程序可以更有效地利用系统资源，避免不需要的阻塞。
    
2.  I/O 阻塞：在许多操作系统中，I/O（输入/输出）操作往往是阻塞的。这意味着在执行 I/O 操作时，程序会等待操作完成才能继续执行后续任务。例如，在从网络或硬盘读取数据时，程序可能会遇到阻塞。为了避免 I/O 阻塞，可以使用异步 I/O 或多线程技术，使得程序在等待 I/O 操作完成的同时，可以执行其他任务。
    
3.  网络阻塞：网络阻塞可能是由于不稳定的网络连接、限制的网络带宽或服务器繁忙等原因导致的。这种阻塞可能导致网络请求延迟或失败，从而影响用户体验和程序功能。为了解决网络阻塞问题，可以采取一些措施，如优化网络架构、使用负载均衡技术、优化网络协议等。
    
4.  资源竞争：在多任务或多线程环境中，多个任务或线程可能会竞争同一资源，例如内存、CPU 时间或其他系统资源。当某个任务或线程获得资源时，其他任务或线程可能会被阻塞，导致不需要的阻塞。为了避免资源竞争导致的阻塞，可以使用同步原语（如互斥锁、信号量等）来确保资源的有序访问，或采用资源调度算法来合理分配资源。
    
5.  软件和硬件限制：某些软件和硬件配置可能会导致不需要的阻塞。例如，操作系统可能会限制并发线程的数量，从而导致线程阻塞；防火墙或安全软件可能会错误地阻止合法的网络连接或程序操作，导致不需要的阻塞。为了解决这些问题，可以：

6.  优化软件配置：检查和优化软件设置，以确保它们不会导致不需要的阻塞。例如，根据系统资源和需求调整操作系统的线程限制，或调整防火墙和安全软件的设置以允许合法操作。
    
7.  硬件升级：在某些情况下，硬件资源不足可能导致不需要的阻塞。升级硬件设备（如增加内存、提高CPU性能、扩展网络带宽等）可以提高系统性能，从而减少不需要的阻塞。
    
8.  代码优化：检查和优化程序代码以减少不需要的阻塞。例如，使用更高效的算法、减少资源竞争、合理使用同步和异步操作等。此外，确保程序具有良好的错误处理机制，以便在遇到阻塞时能够正常运行。
    
9.  负载均衡和缓存：在网络服务中，负载均衡可以有效地分散服务器压力，避免因单个服务器过载导致的不需要的阻塞。同时，使用缓存技术可以减少对原始资源的请求，降低阻塞风险。
    
10.  降级策略：在面临不需要的阻塞时，可以实施降级策略。例如，当某个服务不可用时，可以提供一个基本版本的功能或显示友好的错误消息，以保持程序的正常运行并减轻用户不满。
    

总之，不需要的阻塞可能会对系统性能和用户体验产生负面影响。通过采取措施优化软硬件配置、改进代码质量、实施负载均衡和缓存等策略，可以有效地减少不需要的阻塞，提高程序运行效率。



审阅多线程代码时，一般要思考以下问题

-   Which data needs to be protected from concurrent access?
-   How do you ensure that the data is protected?
-   Where in the code could other threads be at this time?
-   Which mutexes does this thread hold?
-   Which mutexes might other threads hold?
-   Are there any ordering requirements between the operations done in this thread and those done in another? How are those requirements enforced?
-   Is the data loaded by this thread still valid? Could it have been modified by other threads?
-   If you assume that another thread could be modifying the data, what would that mean and how could you ensure that this never happens?


-   如果要测试并发队列，需要考虑以下其情况
    -   One thread calling push() or pop() on its own to verify that the queue works at a basic level
    -   One thread calling push() on an empty queue while another thread calls pop()
    -   Multiple threads calling push() on an empty queue
    -   Multiple threads calling push() on a full queue
    -   Multiple threads calling pop() on an empty queue
    -   Multiple threads calling pop() on a full queue
    -   Multiple threads calling pop() on a partially full queue with insufficient items for all threads
    -   Multiple threads calling push() while one thread calls pop() on an empty queue
    -   Multiple threads calling push() while one thread calls pop() on a full queue
    -   Multiple threads calling push() while multiple threads call pop() on an empty queue
    -   Multiple threads calling push() while multiple threads call pop() on a full queue
-   考虑完以上情况之外，接着就要考虑测试环境的因素
    -   What you mean by “multiple threads” in each case (3, 4, 1,024?)
    -   Whether there are enough processing cores in the system for each thread to run on its own core
    -   Which processor architectures the tests should be run on
    -   How you ensure suitable scheduling for the “while” parts of your tests



## 多线程的测试技术



### 构建多线程测试代码

-   多线程测试代码可以分为以下几部分
    -   必须先执行的总体设置
    -   必须运行在每个线程上的线程特定的设置
    -   要并发运行在每个线程上的代码
    -   并发执行结束后的状态断言
-   如下是对一个队列的测试代码
```cpp
void test_concurrent_push_and_pop_on_empty_queue() {
  ConcurrentQueue<int> q;  // 总体设置：先创建一个队列
  std::promise<void> go, push_ready, pop_ready;
  std::shared_future<void> ready(go.get_future());
  std::future<void> push_done;
  std::future<int> pop_done;
  try {
    push_done = std::async(
        std::launch::async,  // 指定异步策略保证每个任务运行在自己的线程上
        [&q, ready, &push_ready]() {
          push_ready.set_value();
          ready.wait();
          q.push(42);  // 线程特定的设置：存入一个 int
        });
    pop_done = std::async(std::launch::async, [&q, ready, &pop_ready]() {
      pop_ready.set_value();
      ready.wait();
      return q.try_pop();
    });
    push_ready.get_future().wait();  // 等待开始测试的通知
    pop_ready.get_future().wait();   // 同上
    go.set_value();                  // 通知开始真正的测试
    push_done.get();                 // 获取结果
    assert(pop_done.get() == 42);    // 获取结果
    assert(q.empty());
  } catch (...) {
    go.set_value();  // 避免空悬指针
    throw;           // 再抛出异常
  }
}
```
